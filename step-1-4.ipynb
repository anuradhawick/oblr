{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b0bdf71",
   "metadata": {},
   "source": [
    "# Preprocessing Reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6f38b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads path\n",
    "exp = \"./test_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6a5901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming reads\n",
    "!seqtk rename $exp/reads.fastq read_ | seqtk seq -A > $exp/reads.fasta\n",
    "\n",
    "# obtaining read ids\n",
    "!grep \">\" $exp/reads.fasta > $exp/read_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbbc972",
   "metadata": {},
   "source": [
    "# computing 4mers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb1c927",
   "metadata": {},
   "outputs": [],
   "source": [
    "!seq2vec -k 4 -o $exp/4mers -f $exp/reads.fasta -t 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0759b1fd",
   "metadata": {},
   "source": [
    "# Running KBM2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2123bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kbm2  -i $exp/reads.fasta -d $exp/reads.fasta -n 2000 -l 2560 -t 32 | python filter_alignments.py $exp/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1cf74f",
   "metadata": {},
   "source": [
    "# Build Graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bd80b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict, Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from  tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    from cuml.manifold import UMAP\n",
    "    from cuml.metrics.cluster.silhouette_score import cython_silhouette_score as silhouette_score\n",
    "    from cuml.cluster import HDBSCAN\n",
    "    print('Using CUML')\n",
    "except Exception as e:\n",
    "    from sklearn.metrics import silhouette_score\n",
    "    from umap import UMAP\n",
    "    from hdbscan import HDBSCAN\n",
    "    print('Using SciPy', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a339a46d",
   "metadata": {},
   "source": [
    "### essential files from previous steps\n",
    "\n",
    "* ground_truth.txt is optional and only needed for plots and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1c2a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "alignments_file_path = exp + \"reads.alns\"\n",
    "degrees_file_path = exp + \"degree\"\n",
    "\n",
    "comp = pd.read_csv(exp + \"4mers\", delimiter=' ', header=None).to_numpy()\n",
    "\n",
    "try:\n",
    "    truth = np.array(open(exp + \"ground_truth.txt\").read().strip().split(\"\\n\"))\n",
    "except:\n",
    "    truth = np.array([str(0) for x in range(len(comp))])\n",
    "reads = exp + \"reads.fasta\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7107a0",
   "metadata": {},
   "source": [
    "### functions used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc333cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_palette(labels):\n",
    "    palette = {x: f'C{n}' for n, x in enumerate(sorted(set(labels) - {-1, '-1', 'Unknown', 'unknown'}))}\n",
    "    palette['Unknown'] = 'white'\n",
    "    palette['-1'] = 'white'\n",
    "    palette[-1] = 'white'\n",
    "    \n",
    "    return palette\n",
    "\n",
    "\n",
    "def get_idx_maps(read_ids_file_path, truth):\n",
    "    reads_truth = {}\n",
    "    read_id_idx = {}\n",
    "    \n",
    "    with open(read_ids_file_path) as read_ids_file:\n",
    "        for t, rid in tqdm(zip(truth, read_ids_file)):\n",
    "            rid = rid.strip()[1:]\n",
    "            reads_truth[rid] = t\n",
    "            read_id_idx[rid] = len(read_id_idx)\n",
    "            \n",
    "    return reads_truth, read_id_idx\n",
    "\n",
    "\n",
    "def load_read_degrees(degrees_file_path):\n",
    "    degree_array = np.zeros_like(truth, dtype=int)\n",
    "\n",
    "    for line in tqdm(open(degrees_file_path, 'r')):\n",
    "        i, d = line.strip().split()\n",
    "        d = int(d)\n",
    "        degree_array[read_id_idx[i]] = d\n",
    "    \n",
    "    return degree_array\n",
    "\n",
    "\n",
    "def alignments_to_edges(alignments_file_path, edges_txt_path, read_id_idx, reads_truth):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "\n",
    "    if not os.path.isfile(edges_txt_path):\n",
    "        with open(edges_txt_path, \"w+\") as ef:\n",
    "            for line in tqdm(open(alignments_file_path, \"r\")):\n",
    "                u, v = line.strip().split('\\t')\n",
    "\n",
    "                if u == v:\n",
    "                    continue\n",
    "\n",
    "                ef.write(f\"{read_id_idx[u]}\\t{read_id_idx[v]}\\n\")\n",
    "\n",
    "                if reads_truth[u] == 'Unknown' or reads_truth[v] == 'Unknown':\n",
    "                    continue\n",
    "                if reads_truth[u] == reads_truth[v]:\n",
    "                    TP += 1\n",
    "                else:\n",
    "                    FP += 1\n",
    "    return TP, FP\n",
    "\n",
    "\n",
    "def load_edges_as_numpy(edges_txt_path, edges_npy_path):\n",
    "    if not os.path.isfile(edges_npy_path):\n",
    "        edges_txt = [x.strip() for x in tqdm(open(edges_txt_path))]\n",
    "        edges = np.zeros((len(edges_txt), 2), dtype=np.int32)\n",
    "\n",
    "        for i in tqdm(range(len(edges_txt))):\n",
    "            e1, e2 = edges_txt[i].strip().split()\n",
    "            edges[i]  = [int(e1), int(e2)]\n",
    "\n",
    "        np.save(edges_npy_path, edges)\n",
    "        \n",
    "    return np.load(edges_npy_path)\n",
    "\n",
    "\n",
    "def plot_degree_hist(degree, path=None):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    \n",
    "    sns.histplot(degree_array[degree_array>1], binwidth=5) # it must be more than 1 (can have self edges)\n",
    "    plt.ylabel('No. of Vertices', fontsize=18)\n",
    "    plt.xlabel('Degree', fontsize=18)\n",
    "    \n",
    "    if path is not None:\n",
    "        plt.savefig(path, dpi=1200, bbox_inches = 'tight')\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "def plot_umap(embedding, labels, palette=None, path=None, paper=False):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.ylabel('UMAP 2', fontsize=18)\n",
    "    plt.xlabel('UMAP 1', fontsize=18)\n",
    "    \n",
    "    if path is not None and not paper:\n",
    "        sns.scatterplot(x=embedding.T[0], y=embedding.T[1], hue=labels, linewidth=0, alpha=0.5, palette=palette)\n",
    "        plt.legend(bbox_to_anchor=(1,1), loc=\"upper left\")\n",
    "        plt.savefig(path, dpi=1200, bbox_inches = 'tight')\n",
    "    if path is not None and paper:\n",
    "        sns.scatterplot(x=embedding.T[0], y=embedding.T[1], hue=labels, linewidth=0, alpha=0.5, palette=palette, legend=False)\n",
    "        plt.savefig(path.replace('.pdf', '-paper.pdf'), dpi=1200, bbox_inches = 'tight')\n",
    "    else:\n",
    "        sns.scatterplot(x=embedding.T[0], y=embedding.T[1], hue=labels, linewidth=0, alpha=0.5, palette=palette)\n",
    "        plt.legend(bbox_to_anchor=(1,1), loc=\"upper left\")\n",
    "\n",
    "        \n",
    "def get_highest_scoring_clustering(data, size):\n",
    "    best_score = -1\n",
    "    best_clusters = None\n",
    "    best_size = -1\n",
    "    \n",
    "    try:\n",
    "        clusters = HDBSCAN(min_cluster_size=size).fit_predict(data)\n",
    "        if len(set(clusters) - {1}) == 0:\n",
    "            return None, -1, None\n",
    "        score = silhouette_score(data[clusters!=-1], clusters[clusters!=-1])\n",
    "\n",
    "        print(size, score)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_clusters = clusters\n",
    "        best_size = size\n",
    "    \n",
    "    return best_size, best_score, best_clusters\n",
    "\n",
    "\n",
    "def get_best_embedding(data, weights):\n",
    "    best_size = None\n",
    "    best_sample_size = None\n",
    "    best_sample_idx = None\n",
    "    best_score = -1\n",
    "    best_clusters = None\n",
    "    best_embedding = None\n",
    "    best_cluster_count = None\n",
    "    \n",
    "    for sample_size in [25000, 50000, 100000]:\n",
    "        print(f'Scanning sample size {sample_size}')\n",
    "        sample_idx = np.random.choice(range(len(data)), size=sample_size, replace=False, p=weights/weights.sum())\n",
    "        sampled_data = data[sample_idx]\n",
    "        embedding = UMAP().fit_transform(sampled_data)\n",
    "        size, score, clusters = get_highest_scoring_clustering(embedding, 500)\n",
    "        count = len(set(clusters) - {-1})\n",
    "        \n",
    "        print(f'Cluster size = {size:5} Clusters = {count:5} Score = {score:1.5f}')\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_cluster_count = count\n",
    "            best_size = size\n",
    "            best_sample_size = sample_size\n",
    "            best_score = score\n",
    "            best_clusters = clusters\n",
    "            best_embedding = embedding\n",
    "            best_sample_idx = sample_idx\n",
    "            \n",
    "    return best_size, best_sample_size, best_score, best_clusters, best_cluster_count, best_embedding, best_sample_idx\n",
    "\n",
    "\n",
    "def rename_clusters(clusters):\n",
    "    rename_map = {k:n for n, k in enumerate(set(clusters) - {-1})}\n",
    "    rename_map[-1] = -1\n",
    "\n",
    "    clusters = np.array([rename_map[x] for x in clusters])\n",
    "    \n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6ce0a3",
   "metadata": {},
   "source": [
    "### preparing palettes for plotting and maps for read_id index matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5140a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = get_palette(truth)\n",
    "reads_truth, read_id_idx = get_idx_maps(exp + 'read_ids', truth)\n",
    "degree_array = load_read_degrees(degrees_file_path)\n",
    "TP, FP = alignments_to_edges(alignments_file_path, exp + \"edges.txt\", read_id_idx, reads_truth)\n",
    "\n",
    "print(\"Precision of reads (if ground truth provided)\", 100 * TP/ (TP+FP + 1e-5))\n",
    "\n",
    "edges = load_edges_as_numpy(exp + \"edges.txt\", exp + \"edges.npy\")\n",
    "sample_weights = np.zeros_like(degree_array, dtype=np.float32)\n",
    "sample_scale = np.ones_like(degree_array, dtype=np.float32)\n",
    "\n",
    "plot_degree_hist(degree_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c93e1ea",
   "metadata": {},
   "source": [
    "### computing feature scales and probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a80d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, d in enumerate(degree_array):\n",
    "    sample_weights[n] = 1.0/d if d>0 else 0\n",
    "    sample_scale[n] = max(1, np.log10(max(1, d)))\n",
    "    \n",
    "scaled = comp * sample_scale.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57d8158",
   "metadata": {},
   "source": [
    "### searching for the best clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b01278",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for i in range(5):\n",
    "    t_size, t_sample_size, t_score, t_clusters, t_cluster_count, t_embedding, t_sample_idx = get_best_embedding(scaled, sample_weights)\n",
    "    \n",
    "    results.append([t_size, t_sample_size, t_score, t_clusters, t_cluster_count, t_embedding, t_sample_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38400bb",
   "metadata": {},
   "source": [
    "### chosing the best clustering result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13036da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "size, sample_size, score, clusters, cluster_count, embedding, sample_idx = None, None, -1, None, 0, None, None\n",
    "\n",
    "cluster_counts = Counter([result[4] for result in results])\n",
    "cluster_counts = sorted(cluster_counts.most_common(), key=lambda x: (x[1], x[0]), reverse=True)\n",
    "chose = cluster_counts[0][0]\n",
    "\n",
    "print(f\"Count stats = {cluster_counts}\")\n",
    "print(f'Maximally occuring cluster count = {chose}')\n",
    "\n",
    "for result in results:\n",
    "    if result[4] == chose and result[2] > score:\n",
    "        size, sample_size, score, clusters, cluster_count, embedding, sample_idx = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52da4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Chosen Score = {score:3.4f} Sample_size = {sample_size:5} Size = {size} Clusters = {cluster_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69112c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_umap(embedding, truth[sample_idx], palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042ed8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = rename_clusters(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab6ad68",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_umap(embedding[clusters!=-1], [f\"Cluster-{x}\" for x in clusters[clusters!=-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa6e976",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_cluster = np.array([[r, c] for r, c in zip(sample_idx, clusters) if c!=-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3966d305",
   "metadata": {},
   "source": [
    "### carried forward data to the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cb9578",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(exp + 'data.npz', edges=edges, scaled=scaled, read_cluster=read_cluster)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
